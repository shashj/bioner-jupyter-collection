{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b3pB-qEwYMTV",
        "outputId": "9ef500e3-7ddc-4780-97a1-7746ed549fc2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'bioner-jupyter-collection'...\n",
            "remote: Enumerating objects: 184, done.\u001b[K\n",
            "remote: Counting objects: 100% (184/184), done.\u001b[K\n",
            "remote: Compressing objects: 100% (138/138), done.\u001b[K\n",
            "remote: Total 184 (delta 92), reused 111 (delta 40), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (184/184), 2.20 MiB | 10.09 MiB/s, done.\n",
            "Resolving deltas: 100% (92/92), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/shashj/bioner-jupyter-collection.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/bioner-jupyter-collection/SapBert/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aIz5OjruYtNn",
        "outputId": "b7d021ab-6719-4aa2-f183-5eeebe4719a6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/bioner-jupyter-collection/SapBert\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kzT00TPZYxJo",
        "outputId": "3160be19-a358-456e-dc8c-5907e4783137"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/bioner-jupyter-collection/SapBert\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CsM5IdMVYzrn",
        "outputId": "9d04f2b6-d753-4ab3-849c-39b260039477"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Mar 25 07:29:13 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla V100-SXM2-16GB           Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   34C    P0              23W / 300W |      0MiB / 16384MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install accelerate datasets seqeval"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EijtPRV4Y3J9",
        "outputId": "2a037c78-33bc-4ff4-eee2-4db86e64ee14"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting accelerate\n",
            "  Downloading accelerate-0.28.0-py3-none-any.whl (290 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/290.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m286.7/290.1 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.1/290.1 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting datasets\n",
            "  Downloading datasets-2.18.0-py3-none-any.whl (510 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.5/510.5 kB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting seqeval\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (24.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.2.1+cu121)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.20.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.13.1)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.2)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<=2024.2.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.3)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.10/dist-packages (from seqeval) (1.2.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.3.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.3)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m66.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m65.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m91.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.10.0->accelerate)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.10.0->accelerate)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.10.0->accelerate)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.10.0->accelerate)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.10.0->accelerate)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.10.0->accelerate)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu12==2.19.3 (from torch>=1.10.0->accelerate)\n",
            "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.99-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m52.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Building wheels for collected packages: seqeval\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16161 sha256=53ee5378436bdc9280446b7fb67b83ca9be6b0c922eaeb3f92871e85ee8d9049\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/67/4a/ad4082dd7dfc30f2abfe4d80a2ed5926a506eb8a972b4767fa\n",
            "Successfully built seqeval\n",
            "Installing collected packages: xxhash, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, dill, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, seqeval, nvidia-cusolver-cu12, datasets, accelerate\n",
            "Successfully installed accelerate-0.28.0 datasets-2.18.0 dill-0.3.8 multiprocess-0.70.16 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.99 nvidia-nvtx-cu12-12.1.105 seqeval-1.2.2 xxhash-3.4.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python model_train_bc5cdr.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O1TWOm8yZBkc",
        "outputId": "42fd80cd-1de1-4831-e922-f498f4ab6862"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-03-25 07:31:06.908658: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-03-25 07:31:06.908773: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-03-25 07:31:06.947033: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-03-25 07:31:08.165062: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "/content/bioner-jupyter-collection/SapBert/model_train_bc5cdr.py:20: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
            "  metric = load_metric(\"seqeval\")\n",
            "/usr/local/lib/python3.10/dist-packages/datasets/load.py:756: FutureWarning: The repository for seqeval contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/seqeval/seqeval.py\n",
            "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
            "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
            "  warnings.warn(\n",
            "https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/seqeval/seqeval.py not found in cache or force_download set to True, downloading to /root/.cache/huggingface/datasets/downloads/1aec4121eb4fe9daae4cf554d4eba49a1785b14600a9a0d7b23a8461c2e5448f.fef66c5ae9c8e5ceca3a430d2ed4bd43a652202ed179be70ab6d1eb4e8460770.py.incomplete\n",
            "Downloading builder script: 6.33kB [00:00, 13.7MB/s]       \n",
            "storing https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/seqeval/seqeval.py in cache at /root/.cache/huggingface/datasets/downloads/1aec4121eb4fe9daae4cf554d4eba49a1785b14600a9a0d7b23a8461c2e5448f.fef66c5ae9c8e5ceca3a430d2ed4bd43a652202ed179be70ab6d1eb4e8460770.py\n",
            "creating metadata file for /root/.cache/huggingface/datasets/downloads/1aec4121eb4fe9daae4cf554d4eba49a1785b14600a9a0d7b23a8461c2e5448f.fef66c5ae9c8e5ceca3a430d2ed4bd43a652202ed179be70ab6d1eb4e8460770.py\n",
            "Checking /root/.cache/huggingface/datasets/downloads/1aec4121eb4fe9daae4cf554d4eba49a1785b14600a9a0d7b23a8461c2e5448f.fef66c5ae9c8e5ceca3a430d2ed4bd43a652202ed179be70ab6d1eb4e8460770.py for additional imports.\n",
            "Created importable dataset file at /root/.cache/huggingface/modules/datasets_modules/metrics/seqeval/9642e8a602ba52bd4d8baee1d13b2deb8247d3719041cf02b40bf8367a05aef5/seqeval.py\n",
            "No config specified, defaulting to the single config: prep_dataset_bc5cdr/bc5cdr\n",
            "Loading Dataset Infos from /content/bioner-jupyter-collection/SapBert\n",
            "Checking /content/bioner-jupyter-collection/SapBert/prep_dataset_bc5cdr.py for additional imports.\n",
            "Generating dataset prep_dataset_bc5cdr (/root/.cache/huggingface/datasets/prep_dataset_bc5cdr/bc5cdr/1.0.0)\n",
            "Downloading and preparing dataset prep_dataset_bc5cdr/bc5cdr to /root/.cache/huggingface/datasets/prep_dataset_bc5cdr/bc5cdr/1.0.0...\n",
            "Dataset not on Hf google storage. Downloading and preparing it from source\n",
            "https://huggingface.co/datasets/tner/bc5cdr/raw/main/dataset/test.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/datasets/downloads/204247b70ac28e2eb95ead4c51defc10a4a4ed05feafd69252634902806cb9ef.incomplete\n",
            "Downloading data: 100% 1.51M/1.51M [00:00<00:00, 3.63MB/s]\n",
            "storing https://huggingface.co/datasets/tner/bc5cdr/raw/main/dataset/test.json in cache at /root/.cache/huggingface/datasets/downloads/204247b70ac28e2eb95ead4c51defc10a4a4ed05feafd69252634902806cb9ef\n",
            "creating metadata file for /root/.cache/huggingface/datasets/downloads/204247b70ac28e2eb95ead4c51defc10a4a4ed05feafd69252634902806cb9ef\n",
            "https://huggingface.co/datasets/tner/bc5cdr/raw/main/dataset/train.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/datasets/downloads/76477fe11632d9e4ca50d517a1966aa87f9e846a16472f9c9eebbe34219adb14.incomplete\n",
            "Downloading data: 100% 1.42M/1.42M [00:00<00:00, 3.47MB/s]\n",
            "storing https://huggingface.co/datasets/tner/bc5cdr/raw/main/dataset/train.json in cache at /root/.cache/huggingface/datasets/downloads/76477fe11632d9e4ca50d517a1966aa87f9e846a16472f9c9eebbe34219adb14\n",
            "creating metadata file for /root/.cache/huggingface/datasets/downloads/76477fe11632d9e4ca50d517a1966aa87f9e846a16472f9c9eebbe34219adb14\n",
            "https://huggingface.co/datasets/tner/bc5cdr/raw/main/dataset/valid.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/datasets/downloads/bf003c4b0eff039f3d0820549e2ad098feb1f9bd70beeba220ff0235c47168c8.incomplete\n",
            "Downloading data: 100% 1.42M/1.42M [00:00<00:00, 3.49MB/s]\n",
            "storing https://huggingface.co/datasets/tner/bc5cdr/raw/main/dataset/valid.json in cache at /root/.cache/huggingface/datasets/downloads/bf003c4b0eff039f3d0820549e2ad098feb1f9bd70beeba220ff0235c47168c8\n",
            "creating metadata file for /root/.cache/huggingface/datasets/downloads/bf003c4b0eff039f3d0820549e2ad098feb1f9bd70beeba220ff0235c47168c8\n",
            "Downloading took 0.0 min\n",
            "Checksum Computation took 0.0 min\n",
            "Generating train split\n",
            "Generating train split: 4447 examples [00:00, 7525.02 examples/s]Done writing 5228 examples in 1888772 bytes /root/.cache/huggingface/datasets/prep_dataset_bc5cdr/bc5cdr/1.0.0.incomplete/prep_dataset_bc5cdr-train-00000-00000-of-NNNNN.arrow.\n",
            "Generating train split: 5228 examples [00:00, 7446.39 examples/s]\n",
            "Renaming 1 shards.\n",
            "Generating validation split\n",
            "Generating validation split: 4870 examples [00:00, 7860.85 examples/s]Done writing 5330 examples in 1881130 bytes /root/.cache/huggingface/datasets/prep_dataset_bc5cdr/bc5cdr/1.0.0.incomplete/prep_dataset_bc5cdr-validation-00000-00000-of-NNNNN.arrow.\n",
            "Generating validation split: 5330 examples [00:00, 7823.05 examples/s]\n",
            "Renaming 1 shards.\n",
            "Generating test split\n",
            "Generating test split: 5176 examples [00:00, 7898.19 examples/s]Done writing 5865 examples in 2000887 bytes /root/.cache/huggingface/datasets/prep_dataset_bc5cdr/bc5cdr/1.0.0.incomplete/prep_dataset_bc5cdr-test-00000-00000-of-NNNNN.arrow.\n",
            "Generating test split: 5865 examples [00:00, 8007.91 examples/s]\n",
            "Renaming 1 shards.\n",
            "Unable to verify splits sizes.\n",
            "Dataset prep_dataset_bc5cdr downloaded and prepared to /root/.cache/huggingface/datasets/prep_dataset_bc5cdr/bc5cdr/1.0.0. Subsequent calls will reuse this data.\n",
            "Constructing Dataset for split train, validation, test, from /root/.cache/huggingface/datasets/prep_dataset_bc5cdr/bc5cdr/1.0.0\n",
            "tokenizer_config.json: 100% 198/198 [00:00<00:00, 1.10MB/s]\n",
            "config.json: 100% 462/462 [00:00<00:00, 2.22MB/s]\n",
            "vocab.txt: 100% 226k/226k [00:00<00:00, 2.73MB/s]\n",
            "special_tokens_map.json: 100% 112/112 [00:00<00:00, 551kB/s]\n",
            "model.safetensors: 100% 438M/438M [00:01<00:00, 260MB/s]\n",
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at cambridgeltl/SapBERT-from-PubMedBERT-fulltext and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Map:   0% 0/5228 [00:00<?, ? examples/s]Set __getitem__(key) output type to arrow for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
            "Caching processed dataset at /root/.cache/huggingface/datasets/prep_dataset_bc5cdr/bc5cdr/1.0.0/cache-3ccd675753703574.arrow\n",
            "Map:  96% 5000/5228 [00:01<00:00, 3963.27 examples/s]Done writing 5228 examples in 3828260 bytes /root/.cache/huggingface/datasets/prep_dataset_bc5cdr/bc5cdr/1.0.0/tmp985fxunj.\n",
            "Finished processing shard number None of 1.\n",
            "Map: 100% 5228/5228 [00:01<00:00, 4183.24 examples/s]\n",
            "Map:   0% 0/5330 [00:00<?, ? examples/s]Set __getitem__(key) output type to arrow for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
            "Caching processed dataset at /root/.cache/huggingface/datasets/prep_dataset_bc5cdr/bc5cdr/1.0.0/cache-73eec0154a2f979c.arrow\n",
            "Map:  94% 5000/5330 [00:00<00:00, 5557.92 examples/s]Done writing 5330 examples in 3821914 bytes /root/.cache/huggingface/datasets/prep_dataset_bc5cdr/bc5cdr/1.0.0/tmp4ulfgan5.\n",
            "Finished processing shard number None of 1.\n",
            "Map: 100% 5330/5330 [00:00<00:00, 5480.30 examples/s]\n",
            "Map:   0% 0/5865 [00:00<?, ? examples/s]Set __getitem__(key) output type to arrow for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
            "Caching processed dataset at /root/.cache/huggingface/datasets/prep_dataset_bc5cdr/bc5cdr/1.0.0/cache-95726b8467dfa84e.arrow\n",
            "Map: 100% 5865/5865 [00:01<00:00, 5696.42 examples/s]Done writing 5865 examples in 4073599 bytes /root/.cache/huggingface/datasets/prep_dataset_bc5cdr/bc5cdr/1.0.0/tmpylbwh85h.\n",
            "Finished processing shard number None of 1.\n",
            "Map: 100% 5865/5865 [00:01<00:00, 5585.40 examples/s]\n",
            "/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
            "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
            "  warnings.warn(\n",
            " 20% 327/1635 [00:25<01:30, 14.47it/s]\n",
            "  0% 0/334 [00:00<?, ?it/s]\u001b[A\n",
            "  2% 7/334 [00:00<00:05, 64.73it/s]\u001b[A\n",
            "  4% 14/334 [00:00<00:05, 53.51it/s]\u001b[A\n",
            "  6% 20/334 [00:00<00:05, 54.67it/s]\u001b[A\n",
            "  8% 26/334 [00:00<00:06, 50.35it/s]\u001b[A\n",
            " 10% 32/334 [00:00<00:05, 50.66it/s]\u001b[A\n",
            " 11% 38/334 [00:00<00:05, 49.58it/s]\u001b[A\n",
            " 13% 43/334 [00:00<00:05, 48.67it/s]\u001b[A\n",
            " 15% 49/334 [00:00<00:05, 49.53it/s]\u001b[A\n",
            " 16% 54/334 [00:01<00:06, 44.35it/s]\u001b[A\n",
            " 18% 60/334 [00:01<00:05, 46.07it/s]\u001b[A\n",
            " 20% 66/334 [00:01<00:05, 47.34it/s]\u001b[A\n",
            " 21% 71/334 [00:01<00:05, 47.03it/s]\u001b[A\n",
            " 23% 76/334 [00:01<00:05, 47.38it/s]\u001b[A\n",
            " 24% 81/334 [00:01<00:05, 47.25it/s]\u001b[A\n",
            " 26% 87/334 [00:01<00:04, 49.45it/s]\u001b[A\n",
            " 28% 92/334 [00:01<00:05, 45.23it/s]\u001b[A\n",
            " 30% 99/334 [00:02<00:04, 50.89it/s]\u001b[A\n",
            " 31% 105/334 [00:02<00:04, 51.51it/s]\u001b[A\n",
            " 33% 111/334 [00:02<00:04, 53.44it/s]\u001b[A\n",
            " 35% 117/334 [00:02<00:04, 52.93it/s]\u001b[A\n",
            " 37% 123/334 [00:02<00:03, 52.97it/s]\u001b[A\n",
            " 39% 129/334 [00:02<00:04, 48.41it/s]\u001b[A\n",
            " 40% 135/334 [00:02<00:03, 50.15it/s]\u001b[A\n",
            " 42% 141/334 [00:02<00:03, 49.32it/s]\u001b[A\n",
            " 44% 146/334 [00:02<00:04, 46.87it/s]\u001b[A\n",
            " 45% 151/334 [00:03<00:03, 46.23it/s]\u001b[A\n",
            " 47% 156/334 [00:03<00:03, 45.22it/s]\u001b[A\n",
            " 49% 162/334 [00:03<00:03, 47.74it/s]\u001b[A\n",
            " 50% 168/334 [00:03<00:03, 49.21it/s]\u001b[A\n",
            " 52% 173/334 [00:03<00:03, 48.64it/s]\u001b[A\n",
            " 54% 179/334 [00:03<00:03, 51.06it/s]\u001b[A\n",
            " 55% 185/334 [00:03<00:02, 53.23it/s]\u001b[A\n",
            " 57% 191/334 [00:03<00:02, 53.55it/s]\u001b[A\n",
            " 59% 197/334 [00:03<00:02, 52.71it/s]\u001b[A\n",
            " 61% 203/334 [00:04<00:02, 51.90it/s]\u001b[A\n",
            " 63% 209/334 [00:04<00:02, 52.90it/s]\u001b[A\n",
            " 64% 215/334 [00:04<00:02, 51.93it/s]\u001b[A\n",
            " 66% 221/334 [00:04<00:02, 49.44it/s]\u001b[A\n",
            " 68% 227/334 [00:04<00:02, 51.83it/s]\u001b[A\n",
            " 70% 233/334 [00:04<00:02, 47.95it/s]\u001b[A\n",
            " 72% 239/334 [00:04<00:01, 50.71it/s]\u001b[A\n",
            " 73% 245/334 [00:04<00:01, 49.26it/s]\u001b[A\n",
            " 75% 251/334 [00:05<00:01, 51.49it/s]\u001b[A\n",
            " 77% 257/334 [00:05<00:01, 51.16it/s]\u001b[A\n",
            " 79% 263/334 [00:05<00:01, 49.54it/s]\u001b[A\n",
            " 81% 270/334 [00:05<00:01, 53.33it/s]\u001b[A\n",
            " 83% 276/334 [00:05<00:01, 50.21it/s]\u001b[A\n",
            " 84% 282/334 [00:05<00:01, 48.27it/s]\u001b[A\n",
            " 86% 287/334 [00:05<00:01, 41.07it/s]\u001b[A\n",
            " 88% 294/334 [00:05<00:00, 45.24it/s]\u001b[A\n",
            " 90% 300/334 [00:06<00:00, 47.10it/s]\u001b[A\n",
            " 91% 305/334 [00:06<00:00, 46.23it/s]\u001b[A\n",
            " 93% 310/334 [00:06<00:00, 45.05it/s]\u001b[A\n",
            " 94% 315/334 [00:06<00:00, 41.72it/s]\u001b[A\n",
            " 96% 321/334 [00:06<00:00, 44.80it/s]\u001b[A\n",
            " 98% 327/334 [00:06<00:00, 46.89it/s]\u001b[A\n",
            "100% 334/334 [00:06<00:00, 52.58it/s]\u001b[ADone writing 5330 examples in 1619974 bytes /root/.cache/huggingface/metrics/seqeval/default/default_experiment-1-0.arrow.\n",
            "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
            "Removing /root/.cache/huggingface/metrics/seqeval/default/default_experiment-1-0.arrow\n",
            "                                      \n",
            "\u001b[A{'eval_loss': 0.108122818171978, 'eval_precision': 0.8396286258001269, 'eval_recall': 0.8616914245132272, 'eval_f1': 0.85051696944915, 'eval_accuracy': 0.9615182644655224, 'eval_runtime': 10.0259, 'eval_samples_per_second': 531.623, 'eval_steps_per_second': 33.314, 'epoch': 1.0}\n",
            " 20% 327/1635 [00:35<01:30, 14.47it/s]\n",
            "100% 334/334 [00:09<00:00, 52.58it/s]\u001b[A\n",
            "{'loss': 0.1782, 'grad_norm': 1.443329095840454, 'learning_rate': 1.3883792048929665e-05, 'epoch': 1.53}\n",
            " 40% 654/1635 [01:12<01:15, 13.00it/s]\n",
            "  0% 0/334 [00:00<?, ?it/s]\u001b[A\n",
            "  2% 6/334 [00:00<00:05, 58.91it/s]\u001b[A\n",
            "  4% 12/334 [00:00<00:06, 47.65it/s]\u001b[A\n",
            "  5% 18/334 [00:00<00:06, 49.32it/s]\u001b[A\n",
            "  7% 24/334 [00:00<00:06, 44.60it/s]\u001b[A\n",
            "  9% 29/334 [00:00<00:07, 42.87it/s]\u001b[A\n",
            " 10% 34/334 [00:00<00:06, 43.83it/s]\u001b[A\n",
            " 12% 39/334 [00:00<00:07, 40.75it/s]\u001b[A\n",
            " 13% 44/334 [00:01<00:07, 41.07it/s]\u001b[A\n",
            " 15% 49/334 [00:01<00:06, 40.96it/s]\u001b[A\n",
            " 16% 54/334 [00:01<00:07, 38.44it/s]\u001b[A\n",
            " 18% 59/334 [00:01<00:06, 41.17it/s]\u001b[A\n",
            " 19% 64/334 [00:01<00:06, 42.53it/s]\u001b[A\n",
            " 21% 70/334 [00:01<00:05, 45.50it/s]\u001b[A\n",
            " 22% 75/334 [00:01<00:05, 45.24it/s]\u001b[A\n",
            " 24% 80/334 [00:01<00:05, 46.14it/s]\u001b[A\n",
            " 26% 86/334 [00:01<00:05, 49.34it/s]\u001b[A\n",
            " 27% 91/334 [00:02<00:05, 44.46it/s]\u001b[A\n",
            " 29% 98/334 [00:02<00:04, 50.09it/s]\u001b[A\n",
            " 31% 104/334 [00:02<00:04, 50.19it/s]\u001b[A\n",
            " 33% 110/334 [00:02<00:04, 52.82it/s]\u001b[A\n",
            " 35% 116/334 [00:02<00:04, 52.59it/s]\u001b[A\n",
            " 37% 122/334 [00:02<00:04, 52.11it/s]\u001b[A\n",
            " 38% 128/334 [00:02<00:04, 48.36it/s]\u001b[A\n",
            " 40% 134/334 [00:02<00:03, 50.30it/s]\u001b[A\n",
            " 42% 140/334 [00:03<00:03, 49.39it/s]\u001b[A\n",
            " 43% 145/334 [00:03<00:04, 46.37it/s]\u001b[A\n",
            " 45% 150/334 [00:03<00:04, 45.95it/s]\u001b[A\n",
            " 46% 155/334 [00:03<00:03, 45.53it/s]\u001b[A\n",
            " 48% 160/334 [00:03<00:03, 46.06it/s]\u001b[A\n",
            " 50% 166/334 [00:03<00:03, 48.97it/s]\u001b[A\n",
            " 51% 172/334 [00:03<00:03, 48.82it/s]\u001b[A\n",
            " 54% 179/334 [00:03<00:02, 52.47it/s]\u001b[A\n",
            " 55% 185/334 [00:03<00:02, 53.86it/s]\u001b[A\n",
            " 57% 191/334 [00:04<00:02, 54.74it/s]\u001b[A\n",
            " 59% 197/334 [00:04<00:02, 53.44it/s]\u001b[A\n",
            " 61% 203/334 [00:04<00:02, 51.09it/s]\u001b[A\n",
            " 63% 209/334 [00:04<00:02, 51.39it/s]\u001b[A\n",
            " 64% 215/334 [00:04<00:02, 50.96it/s]\u001b[A\n",
            " 66% 221/334 [00:04<00:02, 48.69it/s]\u001b[A\n",
            " 68% 227/334 [00:04<00:02, 50.91it/s]\u001b[A\n",
            " 70% 233/334 [00:04<00:02, 47.75it/s]\u001b[A\n",
            " 72% 239/334 [00:04<00:01, 50.59it/s]\u001b[A\n",
            " 73% 245/334 [00:05<00:01, 49.19it/s]\u001b[A\n",
            " 75% 251/334 [00:05<00:01, 51.78it/s]\u001b[A\n",
            " 77% 257/334 [00:05<00:01, 51.37it/s]\u001b[A\n",
            " 79% 263/334 [00:05<00:01, 49.61it/s]\u001b[A\n",
            " 81% 270/334 [00:05<00:01, 53.11it/s]\u001b[A\n",
            " 83% 276/334 [00:05<00:01, 50.25it/s]\u001b[A\n",
            " 84% 282/334 [00:05<00:01, 49.28it/s]\u001b[A\n",
            " 86% 287/334 [00:06<00:01, 41.48it/s]\u001b[A\n",
            " 88% 293/334 [00:06<00:00, 45.38it/s]\u001b[A\n",
            " 90% 299/334 [00:06<00:00, 47.56it/s]\u001b[A\n",
            " 91% 305/334 [00:06<00:00, 46.01it/s]\u001b[A\n",
            " 93% 310/334 [00:06<00:00, 44.25it/s]\u001b[A\n",
            " 94% 315/334 [00:06<00:00, 41.14it/s]\u001b[A\n",
            " 96% 321/334 [00:06<00:00, 44.50it/s]\u001b[A\n",
            " 98% 327/334 [00:06<00:00, 47.49it/s]\u001b[A\n",
            "100% 334/334 [00:06<00:00, 53.34it/s]\u001b[ADone writing 5330 examples in 1620378 bytes /root/.cache/huggingface/metrics/seqeval/default/default_experiment-1-0.arrow.\n",
            "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
            "Removing /root/.cache/huggingface/metrics/seqeval/default/default_experiment-1-0.arrow\n",
            "                                      \n",
            "\u001b[A{'eval_loss': 0.09984351694583893, 'eval_precision': 0.8782889055213311, 'eval_recall': 0.9028229863289341, 'eval_f1': 0.8903869725091927, 'eval_accuracy': 0.9680905182316453, 'eval_runtime': 10.0747, 'eval_samples_per_second': 529.046, 'eval_steps_per_second': 33.152, 'epoch': 2.0}\n",
            " 40% 654/1635 [01:22<01:15, 13.00it/s]\n",
            "100% 334/334 [00:10<00:00, 53.34it/s]\u001b[A\n",
            " 60% 980/1635 [01:46<00:47, 13.68it/s]\n",
            "  0% 0/334 [00:00<?, ?it/s]\u001b[A\n",
            "  2% 7/334 [00:00<00:04, 66.26it/s]\u001b[A\n",
            "  4% 14/334 [00:00<00:05, 53.78it/s]\u001b[A\n",
            "  6% 20/334 [00:00<00:05, 55.71it/s]\u001b[A\n",
            "  8% 26/334 [00:00<00:06, 50.77it/s]\u001b[A\n",
            " 10% 32/334 [00:00<00:05, 51.35it/s]\u001b[A\n",
            " 11% 38/334 [00:00<00:05, 50.02it/s]\u001b[A\n",
            " 13% 44/334 [00:00<00:06, 45.89it/s]\u001b[A\n",
            " 15% 49/334 [00:01<00:06, 44.86it/s]\u001b[A\n",
            " 16% 54/334 [00:01<00:06, 40.47it/s]\u001b[A\n",
            " 18% 59/334 [00:01<00:06, 41.29it/s]\u001b[A\n",
            " 19% 64/334 [00:01<00:06, 41.84it/s]\u001b[A\n",
            " 21% 69/334 [00:01<00:06, 43.15it/s]\u001b[A\n",
            " 22% 74/334 [00:01<00:06, 42.67it/s]\u001b[A\n",
            " 24% 79/334 [00:01<00:06, 42.30it/s]\u001b[A\n",
            " 25% 85/334 [00:01<00:05, 44.86it/s]\u001b[A\n",
            " 27% 90/334 [00:02<00:06, 40.34it/s]\u001b[A\n",
            " 29% 96/334 [00:02<00:05, 43.58it/s]\u001b[A\n",
            " 30% 101/334 [00:02<00:05, 44.58it/s]\u001b[A\n",
            " 32% 106/334 [00:02<00:05, 44.51it/s]\u001b[A\n",
            " 33% 111/334 [00:02<00:04, 44.63it/s]\u001b[A\n",
            " 35% 116/334 [00:02<00:04, 44.25it/s]\u001b[A\n",
            " 36% 121/334 [00:02<00:05, 42.22it/s]\u001b[A\n",
            " 38% 126/334 [00:02<00:04, 41.78it/s]\u001b[A\n",
            " 39% 131/334 [00:02<00:04, 41.51it/s]\u001b[A\n",
            " 41% 137/334 [00:03<00:04, 44.35it/s]\u001b[A\n",
            " 43% 142/334 [00:03<00:04, 44.00it/s]\u001b[A\n",
            " 44% 147/334 [00:03<00:04, 42.33it/s]\u001b[A\n",
            " 46% 152/334 [00:03<00:04, 43.35it/s]\u001b[A\n",
            " 47% 157/334 [00:03<00:04, 43.39it/s]\u001b[A\n",
            " 49% 163/334 [00:03<00:03, 46.61it/s]\u001b[A\n",
            " 51% 169/334 [00:03<00:03, 48.30it/s]\u001b[A\n",
            " 52% 174/334 [00:03<00:03, 48.37it/s]\u001b[A\n",
            " 54% 180/334 [00:03<00:02, 51.35it/s]\u001b[A\n",
            " 56% 186/334 [00:04<00:02, 53.58it/s]\u001b[A\n",
            " 57% 192/334 [00:04<00:02, 54.04it/s]\u001b[A\n",
            " 59% 198/334 [00:04<00:02, 52.47it/s]\u001b[A\n",
            " 61% 204/334 [00:04<00:02, 52.94it/s]\u001b[A\n",
            " 63% 210/334 [00:04<00:02, 51.49it/s]\u001b[A\n",
            " 65% 217/334 [00:04<00:02, 52.64it/s]\u001b[A\n",
            " 67% 223/334 [00:04<00:02, 50.42it/s]\u001b[A\n",
            " 69% 229/334 [00:04<00:02, 50.17it/s]\u001b[A\n",
            " 70% 235/334 [00:05<00:01, 49.60it/s]\u001b[A\n",
            " 72% 241/334 [00:05<00:01, 50.93it/s]\u001b[A\n",
            " 74% 247/334 [00:05<00:01, 49.29it/s]\u001b[A\n",
            " 76% 254/334 [00:05<00:01, 52.43it/s]\u001b[A\n",
            " 78% 260/334 [00:05<00:01, 50.00it/s]\u001b[A\n",
            " 80% 266/334 [00:05<00:01, 50.80it/s]\u001b[A\n",
            " 82% 273/334 [00:05<00:01, 52.96it/s]\u001b[A\n",
            " 84% 279/334 [00:05<00:01, 48.68it/s]\u001b[A\n",
            " 85% 284/334 [00:06<00:01, 41.83it/s]\u001b[A\n",
            " 87% 290/334 [00:06<00:01, 43.68it/s]\u001b[A\n",
            " 89% 296/334 [00:06<00:00, 47.35it/s]\u001b[A\n",
            " 90% 301/334 [00:06<00:00, 47.34it/s]\u001b[A\n",
            " 92% 306/334 [00:06<00:00, 45.70it/s]\u001b[A\n",
            " 93% 311/334 [00:06<00:00, 44.63it/s]\u001b[A\n",
            " 95% 316/334 [00:06<00:00, 41.42it/s]\u001b[A\n",
            " 96% 322/334 [00:06<00:00, 44.83it/s]\u001b[A\n",
            " 98% 328/334 [00:07<00:00, 46.11it/s]\u001b[ADone writing 5330 examples in 1620298 bytes /root/.cache/huggingface/metrics/seqeval/default/default_experiment-1-0.arrow.\n",
            "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
            "Removing /root/.cache/huggingface/metrics/seqeval/default/default_experiment-1-0.arrow\n",
            "                                      \n",
            "\u001b[A{'eval_loss': 0.10081290453672409, 'eval_precision': 0.8851599074961927, 'eval_recall': 0.9287447475883293, 'eval_f1': 0.9064286952001386, 'eval_accuracy': 0.971536643801897, 'eval_runtime': 10.19, 'eval_samples_per_second': 523.063, 'eval_steps_per_second': 32.777, 'epoch': 3.0}\n",
            " 60% 981/1635 [01:56<00:47, 13.68it/s]\n",
            "100% 334/334 [00:10<00:00, 46.11it/s]\u001b[A\n",
            "{'loss': 0.0499, 'grad_norm': 0.9984935522079468, 'learning_rate': 7.767584097859327e-06, 'epoch': 3.06}\n",
            " 80% 1308/1635 [02:30<00:24, 13.37it/s]\n",
            "  0% 0/334 [00:00<?, ?it/s]\u001b[A\n",
            "  2% 7/334 [00:00<00:05, 60.36it/s]\u001b[A\n",
            "  4% 14/334 [00:00<00:06, 51.65it/s]\u001b[A\n",
            "  6% 21/334 [00:00<00:05, 55.28it/s]\u001b[A\n",
            "  8% 27/334 [00:00<00:06, 49.83it/s]\u001b[A\n",
            " 10% 33/334 [00:00<00:05, 51.21it/s]\u001b[A\n",
            " 12% 39/334 [00:00<00:05, 49.21it/s]\u001b[A\n",
            " 13% 44/334 [00:00<00:05, 49.40it/s]\u001b[A\n",
            " 15% 49/334 [00:00<00:05, 49.07it/s]\u001b[A\n",
            " 16% 54/334 [00:01<00:06, 44.11it/s]\u001b[A\n",
            " 18% 59/334 [00:01<00:06, 45.60it/s]\u001b[A\n",
            " 19% 64/334 [00:01<00:05, 45.98it/s]\u001b[A\n",
            " 21% 70/334 [00:01<00:05, 48.28it/s]\u001b[A\n",
            " 22% 75/334 [00:01<00:05, 47.18it/s]\u001b[A\n",
            " 24% 80/334 [00:01<00:05, 47.34it/s]\u001b[A\n",
            " 26% 86/334 [00:01<00:04, 50.82it/s]\u001b[A\n",
            " 28% 92/334 [00:01<00:05, 45.44it/s]\u001b[A\n",
            " 30% 99/334 [00:02<00:04, 50.99it/s]\u001b[A\n",
            " 31% 105/334 [00:02<00:04, 51.27it/s]\u001b[A\n",
            " 33% 111/334 [00:02<00:04, 53.43it/s]\u001b[A\n",
            " 35% 117/334 [00:02<00:04, 53.62it/s]\u001b[A\n",
            " 37% 123/334 [00:02<00:03, 53.30it/s]\u001b[A\n",
            " 39% 129/334 [00:02<00:04, 48.83it/s]\u001b[A\n",
            " 40% 135/334 [00:02<00:03, 50.41it/s]\u001b[A\n",
            " 42% 141/334 [00:02<00:03, 49.13it/s]\u001b[A\n",
            " 44% 146/334 [00:02<00:04, 46.64it/s]\u001b[A\n",
            " 45% 151/334 [00:03<00:03, 45.97it/s]\u001b[A\n",
            " 47% 156/334 [00:03<00:03, 44.90it/s]\u001b[A\n",
            " 49% 162/334 [00:03<00:03, 47.50it/s]\u001b[A\n",
            " 50% 168/334 [00:03<00:03, 48.85it/s]\u001b[A\n",
            " 52% 173/334 [00:03<00:03, 49.01it/s]\u001b[A\n",
            " 54% 180/334 [00:03<00:02, 53.14it/s]\u001b[A\n",
            " 56% 186/334 [00:03<00:02, 54.73it/s]\u001b[A\n",
            " 57% 192/334 [00:03<00:02, 54.57it/s]\u001b[A\n",
            " 59% 198/334 [00:03<00:02, 52.76it/s]\u001b[A\n",
            " 61% 204/334 [00:04<00:02, 52.75it/s]\u001b[A\n",
            " 63% 210/334 [00:04<00:02, 50.77it/s]\u001b[A\n",
            " 65% 217/334 [00:04<00:02, 52.15it/s]\u001b[A\n",
            " 67% 223/334 [00:04<00:02, 50.41it/s]\u001b[A\n",
            " 69% 229/334 [00:04<00:02, 50.50it/s]\u001b[A\n",
            " 70% 235/334 [00:04<00:01, 50.49it/s]\u001b[A\n",
            " 72% 241/334 [00:04<00:01, 51.74it/s]\u001b[A\n",
            " 74% 247/334 [00:04<00:01, 49.98it/s]\u001b[A\n",
            " 76% 254/334 [00:05<00:01, 52.59it/s]\u001b[A\n",
            " 78% 260/334 [00:05<00:01, 49.75it/s]\u001b[A\n",
            " 80% 266/334 [00:05<00:01, 48.28it/s]\u001b[A\n",
            " 81% 272/334 [00:05<00:01, 49.04it/s]\u001b[A\n",
            " 83% 277/334 [00:05<00:01, 45.43it/s]\u001b[A\n",
            " 84% 282/334 [00:05<00:01, 44.30it/s]\u001b[A\n",
            " 86% 287/334 [00:05<00:01, 36.84it/s]\u001b[A\n",
            " 87% 292/334 [00:06<00:01, 39.54it/s]\u001b[A\n",
            " 89% 298/334 [00:06<00:00, 43.02it/s]\u001b[A\n",
            " 91% 303/334 [00:06<00:00, 42.64it/s]\u001b[A\n",
            " 92% 308/334 [00:06<00:00, 40.07it/s]\u001b[A\n",
            " 94% 313/334 [00:06<00:00, 38.53it/s]\u001b[A\n",
            " 95% 317/334 [00:06<00:00, 38.77it/s]\u001b[A\n",
            " 96% 322/334 [00:06<00:00, 40.89it/s]\u001b[A\n",
            " 98% 327/334 [00:06<00:00, 40.48it/s]\u001b[A\n",
            "100% 333/334 [00:06<00:00, 43.28it/s]\u001b[ADone writing 5330 examples in 1619314 bytes /root/.cache/huggingface/metrics/seqeval/default/default_experiment-1-0.arrow.\n",
            "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
            "Removing /root/.cache/huggingface/metrics/seqeval/default/default_experiment-1-0.arrow\n",
            "                                       \n",
            "\u001b[A{'eval_loss': 0.10662014782428741, 'eval_precision': 0.8985665764780381, 'eval_recall': 0.9237734509084453, 'eval_f1': 0.9109956811019027, 'eval_accuracy': 0.9722012537333027, 'eval_runtime': 10.2895, 'eval_samples_per_second': 518.006, 'eval_steps_per_second': 32.46, 'epoch': 4.0}\n",
            " 80% 1308/1635 [02:40<00:24, 13.37it/s]\n",
            "100% 334/334 [00:10<00:00, 43.28it/s]\u001b[A\n",
            "{'loss': 0.0235, 'grad_norm': 2.478346586227417, 'learning_rate': 1.6513761467889911e-06, 'epoch': 4.59}\n",
            "100% 1634/1635 [03:10<00:00, 14.57it/s]\n",
            "  0% 0/334 [00:00<?, ?it/s]\u001b[A\n",
            "  2% 7/334 [00:00<00:04, 66.29it/s]\u001b[A\n",
            "  4% 14/334 [00:00<00:05, 53.84it/s]\u001b[A\n",
            "  6% 21/334 [00:00<00:05, 56.42it/s]\u001b[A\n",
            "  8% 27/334 [00:00<00:06, 50.69it/s]\u001b[A\n",
            " 10% 33/334 [00:00<00:05, 52.11it/s]\u001b[A\n",
            " 12% 39/334 [00:00<00:05, 49.51it/s]\u001b[A\n",
            " 13% 45/334 [00:00<00:06, 47.01it/s]\u001b[A\n",
            " 15% 50/334 [00:01<00:06, 44.15it/s]\u001b[A\n",
            " 16% 55/334 [00:01<00:06, 40.05it/s]\u001b[A\n",
            " 18% 60/334 [00:01<00:06, 41.88it/s]\u001b[A\n",
            " 19% 65/334 [00:01<00:06, 42.83it/s]\u001b[A\n",
            " 21% 70/334 [00:01<00:06, 43.98it/s]\u001b[A\n",
            " 22% 75/334 [00:01<00:06, 42.48it/s]\u001b[A\n",
            " 24% 80/334 [00:01<00:05, 42.73it/s]\u001b[A\n",
            " 26% 86/334 [00:01<00:05, 46.03it/s]\u001b[A\n",
            " 27% 91/334 [00:02<00:05, 41.04it/s]\u001b[A\n",
            " 29% 96/334 [00:02<00:05, 42.02it/s]\u001b[A\n",
            " 30% 101/334 [00:02<00:05, 42.48it/s]\u001b[A\n",
            " 32% 106/334 [00:02<00:05, 42.87it/s]\u001b[A\n",
            " 33% 111/334 [00:02<00:05, 44.07it/s]\u001b[A\n",
            " 35% 116/334 [00:02<00:04, 44.06it/s]\u001b[A\n",
            " 36% 121/334 [00:02<00:04, 42.74it/s]\u001b[A\n",
            " 38% 126/334 [00:02<00:04, 41.82it/s]\u001b[A\n",
            " 39% 131/334 [00:02<00:04, 41.75it/s]\u001b[A\n",
            " 41% 136/334 [00:03<00:04, 43.82it/s]\u001b[A\n",
            " 42% 141/334 [00:03<00:04, 44.62it/s]\u001b[A\n",
            " 44% 146/334 [00:03<00:04, 43.61it/s]\u001b[A\n",
            " 45% 151/334 [00:03<00:04, 43.91it/s]\u001b[A\n",
            " 47% 156/334 [00:03<00:04, 43.39it/s]\u001b[A\n",
            " 49% 162/334 [00:03<00:03, 46.22it/s]\u001b[A\n",
            " 50% 168/334 [00:03<00:03, 48.17it/s]\u001b[A\n",
            " 52% 173/334 [00:03<00:03, 48.26it/s]\u001b[A\n",
            " 54% 180/334 [00:03<00:02, 52.43it/s]\u001b[A\n",
            " 56% 186/334 [00:04<00:02, 53.88it/s]\u001b[A\n",
            " 57% 192/334 [00:04<00:02, 52.52it/s]\u001b[A\n",
            " 59% 198/334 [00:04<00:02, 51.47it/s]\u001b[A\n",
            " 61% 204/334 [00:04<00:02, 52.23it/s]\u001b[A\n",
            " 63% 210/334 [00:04<00:02, 50.82it/s]\u001b[A\n",
            " 65% 217/334 [00:04<00:02, 52.06it/s]\u001b[A\n",
            " 67% 223/334 [00:04<00:02, 50.43it/s]\u001b[A\n",
            " 69% 229/334 [00:04<00:02, 50.77it/s]\u001b[A\n",
            " 70% 235/334 [00:05<00:01, 50.75it/s]\u001b[A\n",
            " 72% 241/334 [00:05<00:01, 50.80it/s]\u001b[A\n",
            " 74% 247/334 [00:05<00:01, 48.42it/s]\u001b[A\n",
            " 76% 254/334 [00:05<00:01, 51.47it/s]\u001b[A\n",
            " 78% 260/334 [00:05<00:01, 49.09it/s]\u001b[A\n",
            " 80% 266/334 [00:05<00:01, 50.35it/s]\u001b[A\n",
            " 82% 273/334 [00:05<00:01, 52.35it/s]\u001b[A\n",
            " 84% 279/334 [00:05<00:01, 48.14it/s]\u001b[A\n",
            " 85% 284/334 [00:06<00:01, 42.26it/s]\u001b[A\n",
            " 87% 289/334 [00:06<00:01, 43.29it/s]\u001b[A\n",
            " 88% 295/334 [00:06<00:00, 46.38it/s]\u001b[A\n",
            " 90% 300/334 [00:06<00:00, 47.19it/s]\u001b[A\n",
            " 91% 305/334 [00:06<00:00, 46.74it/s]\u001b[A\n",
            " 93% 310/334 [00:06<00:00, 44.79it/s]\u001b[A\n",
            " 94% 315/334 [00:06<00:00, 41.03it/s]\u001b[A\n",
            " 96% 321/334 [00:06<00:00, 44.06it/s]\u001b[A\n",
            " 98% 327/334 [00:06<00:00, 47.22it/s]\u001b[A\n",
            "100% 334/334 [00:07<00:00, 52.57it/s]\u001b[ADone writing 5330 examples in 1620539 bytes /root/.cache/huggingface/metrics/seqeval/default/default_experiment-1-0.arrow.\n",
            "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
            "Removing /root/.cache/huggingface/metrics/seqeval/default/default_experiment-1-0.arrow\n",
            "                                       \n",
            "\u001b[A{'eval_loss': 0.11251255124807358, 'eval_precision': 0.8944187902628128, 'eval_recall': 0.9285080191750015, 'eval_f1': 0.9111446657761774, 'eval_accuracy': 0.9720207423939086, 'eval_runtime': 10.2149, 'eval_samples_per_second': 521.786, 'eval_steps_per_second': 32.697, 'epoch': 5.0}\n",
            "100% 1635/1635 [03:20<00:00, 14.57it/s]\n",
            "100% 334/334 [00:10<00:00, 52.57it/s]\u001b[A\n",
            "{'train_runtime': 200.9072, 'train_samples_per_second': 130.11, 'train_steps_per_second': 8.138, 'train_loss': 0.0785618013562777, 'epoch': 5.0}\n",
            "100% 1635/1635 [03:20<00:00,  8.14it/s]\n",
            " 99% 331/334 [00:07<00:00, 50.23it/s]Done writing 5330 examples in 1620539 bytes /root/.cache/huggingface/metrics/seqeval/default/default_experiment-1-0.arrow.\n",
            "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
            "Removing /root/.cache/huggingface/metrics/seqeval/default/default_experiment-1-0.arrow\n",
            "100% 334/334 [00:10<00:00, 31.83it/s]\n",
            " 99% 362/367 [00:07<00:00, 49.44it/s]Done writing 5865 examples in 1705772 bytes /root/.cache/huggingface/metrics/seqeval/default/default_experiment-1-0.arrow.\n",
            "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
            "Removing /root/.cache/huggingface/metrics/seqeval/default/default_experiment-1-0.arrow\n",
            "100% 367/367 [00:10<00:00, 35.03it/s]\n",
            "Done writing 5865 examples in 1705772 bytes /root/.cache/huggingface/metrics/seqeval/default/default_experiment-1-0.arrow.\n",
            "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
            "Removing /root/.cache/huggingface/metrics/seqeval/default/default_experiment-1-0.arrow\n",
            "{'Chemical': {'precision': 0.9115748518878769, 'recall': 0.9478668628172122, 'f1': 0.9293666892044173, 'number': 10876}, 'Disease': {'precision': 0.7931394481730052, 'recall': 0.857741935483871, 'f1': 0.8241766757070904, 'number': 6200}, 'overall_precision': 0.8674919507050072, 'overall_recall': 0.9151440618411806, 'overall_f1': 0.8906811057281276, 'overall_accuracy': 0.9677899674427934}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UYyErEM-ZMMI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}